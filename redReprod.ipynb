{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc1a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Reshape, Layer\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5b6bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "class Replicar(Sequential):\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker] \n",
    "\n",
    "    def train_step(self, data):\n",
    "        def funcA(x):\n",
    "            return tf.math.sin(np.pi*x)*3\n",
    "\n",
    "        def funcB(x):\n",
    "            return 1 + 2*x + 4*x**3\n",
    "\n",
    "        interval = [-1, 1]\n",
    "        batch_size = 100 #Calibra la resolucion\n",
    "        x = tf.random.uniform((batch_size, 1), minval=-1, maxval=1)\n",
    "        inter = np.linspace(interval, 100)\n",
    "        vals = funcA(inter).astype(np.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = tf.math.reduce_mean(tf.math.square(y_pred-vals))\n",
    "\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\": loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c60a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcA(x):\n",
    "    return tf.math.sin(np.pi*x)*3\n",
    "\n",
    "def funcB(x):\n",
    "    return 1 + 2*x + 4*x**3\n",
    "\n",
    "def noise(f, x):\n",
    "    vals = f(x)\n",
    "    for i in vals:\n",
    "        vals += random.uniform(-0.3, 0.3)\n",
    "    return vals\n",
    "\n",
    "interval = [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3618a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"replicar_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 600)               1200      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 200)               120200    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,801\n",
      "Trainable params: 161,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Replicar([\n",
    "    Dense(600,activation='tanh', input_shape=(1,)),\n",
    "    Dense(200,activation='tanh'),\n",
    "    Dense(200,activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b48318e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_12552\\1954137025.py\", line 24, in train_step\n        loss = tf.math.reduce_mean(tf.math.square(y_pred-vals))\n\n    ValueError: Dimensions must be equal, but are 100 and 50 for '{{node sub}} = Sub[T=DT_FLOAT](replicar_8/dense_31/BiasAdd, Cast)' with input shapes: [100,1], [50,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dummy_data \u001b[38;5;241m=\u001b[39m noise(funcA, np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m))  \u001b[38;5;66;03m# Replace with your data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filei2i0y6e1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[62], line 24\u001b[0m, in \u001b[0;36mReplicar.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     23\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mvals\u001b[49m))\n\u001b[0;32m     26\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_weights))\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_12552\\1954137025.py\", line 24, in train_step\n        loss = tf.math.reduce_mean(tf.math.square(y_pred-vals))\n\n    ValueError: Dimensions must be equal, but are 100 and 50 for '{{node sub}} = Sub[T=DT_FLOAT](replicar_8/dense_31/BiasAdd, Cast)' with input shapes: [100,1], [50,2].\n"
     ]
    }
   ],
   "source": [
    "dummy_data = noise(funcA, np.linspace(-1, 1, 100))  # Replace with your data\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), metrics=['loss'])\n",
    "history = model.fit(dummy_data, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c3ac702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float64, numpy=\n",
       "array([ 1.47082722,  1.28055546,  1.09104986,  0.90307348,  0.71738326,\n",
       "        0.53472688,  0.35583985,  0.18144248,  0.01223701, -0.15109523,\n",
       "       -0.30789657, -0.45753561, -0.59940982, -0.73294791, -0.85761217,\n",
       "       -0.97290064, -1.07834907, -1.17353287, -1.25806877, -1.33161636,\n",
       "       -1.39387951, -1.44460749, -1.48359604, -1.51068818, -1.5257748 ,\n",
       "       -1.52879517, -1.51973711, -1.49863711, -1.46558012, -1.42069926,\n",
       "       -1.36417524, -1.29623566, -1.2171541 , -1.12724899, -1.02688235,\n",
       "       -0.9164583 , -0.79642151, -0.6672553 , -0.52947978, -0.38364974,\n",
       "       -0.23035237, -0.07020496,  0.09614765,  0.26803561,  0.44476679,\n",
       "        0.62562955,  0.80989562,  0.99682303,  1.18565909,  1.37564342,\n",
       "        1.56601102,  1.75599535,  1.94483141,  2.13175882,  2.31602489,\n",
       "        2.49688765,  2.67361882,  2.84550678,  3.01185939,  3.17200681,\n",
       "        3.32530418,  3.47113422,  3.60890973,  3.73807594,  3.85811274,\n",
       "        3.96853678,  4.06890343,  4.15880854,  4.2378901 ,  4.30582967,\n",
       "        4.36235369,  4.40723456,  4.44029154,  4.46139155,  4.4704496 ,\n",
       "        4.46742924,  4.45234261,  4.42525048,  4.38626192,  4.33553394,\n",
       "        4.2732708 ,  4.1997232 ,  4.11518731,  4.02000351,  3.91455507,\n",
       "        3.79926661,  3.67460234,  3.54106425,  3.39919005,  3.24955101,\n",
       "        3.09274967,  2.92941743,  2.76021195,  2.58581458,  2.40692756,\n",
       "        2.22427118,  2.03858095,  1.85060458,  1.66109898,  1.47082722])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd92343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
